■Cost function
-이론-
비용함수는 간단히 보면 그냥 현재 있는 hypothesis를 실제 결과값에 비해서 나온 에러값을 구해주는 함수를 말한다.

비용함수는 함수이다. 즉 그래프로 그려서 나타낼 수 있다. 즉, 가중치를 변경하려고 할 때에 필요한 식을 간단하게 도출해내기 위해 도움이 된다.

-물리-
비용함수는 전체 데이터셋에 각각에 대한 예측값을 그 각각의 실제 결값과의 차이를 더한것을 평균을 낸 것을 구하는 것을 말한다.



■Backpropagation & Chain rule
역전파는 딥한 신경망에 있어서 출력값과 실제값의 오차를 처음의 레이어까지 전달 하기 위해 사용되는 알고리즘이다.

(기본적으로 Gradient Descent를 기준으로 하게 되는 것이다.)

(매우중요)오차를 해당 w로 미분한 값을 기존의 w에 적용하는게 학습인데 은닉층의 w들은 실제값이라는
비교할 값이 없어서 오차조차 구할 수가 없고 그렇게 되면 학습이 불가능 해지는 것임
이 문제를 Chain rule을 통해 마지막 층의 결과의 오차로부터 미분을 해서 은닉층의 w들을 학습시켜주는 원리임

Chain rule을 사용하게 된다. (이게 매우 핵심적인 기술임 Backpropagation의)
(Chain rule은 미분과 관련된 규칙이다.)

미분값이 왜 영향력이냐의 문제는 다음과 같다.
미분값 = 기울기 = 영향력
기울기(대각선)가 = cost x 변수(w or b)이기 때문

Chian rule에서 곱셈(*)의 관계는 영향을 (엄청)미치고 덧셈(*)의 관계는 영향을 미치지 않게 된다.
여기에서 추론할 수 있는 바는 다음과 같다.
1. 인공신경망 or 딥러닝 이 쪽의 모든 hypothesis들은 곱셈으로 입력값들과 w값들이 연결되어 있다.
즉, 오차가 발생했을 때 입력값이 큰 곳의 w가 굉장히 많이 벌을 받게 된다. (값이 클수록 영향을 많이 미친것인데 그 결과가 틀린것이므로)

최종 결과에 미치는 영향력은 식이 굉장히 깊을 때 맨 첫단으로 향할수록 커진다.



■Restricted Boatman Machine(RBM)
RBM이란 학습을 빠르고 더 정확하게 시키기 위해 초기 웨이트값을 무작위로 주는 것이 아닌 적절한 값으로 초기화를 해놓기 위해 쓰이는 방법이다.
그 방법은 다음과 같다.
1. 입력층과 첫번째 은닉층 사이의 w값을 랜덤값으로 준다.
2. 입력층에서 w값과 각각 연결되어 결과값을 만들고
3. 그 결과값에 역으로 또 입력층과 은닉층 사이의 w값과 연결해서 입력값하고 같은지를 비교
4. 같지 않으면 w값을 같아질때까지 반복한다.
5. 같아지면 그 다음 층하고 또 위의 과정을 반복한다.
6. 마지막 층까지 이렇게 w값을 조정을 한다.

흔히 RBM을 쓴 학습 방법을 Deep Belief Net이라고 부른다.